{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pysa.emd as emddev\n",
    "import pysa.eemd as eemddev\n",
    "import pysa.visualization as plotter\n",
    "import pysa.utils as utils\n",
    "import pysa.nhht as nhht\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import os\n",
    "from scipy import fft\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "test = 1\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF_filter(signal):\n",
    "    max_modes = 15\n",
    "    ensembles = 100\n",
    "    ensembles_per_process = 10\n",
    "    max_siftings = 200\n",
    "    end_time = 10\n",
    "    sample_freq = 250\n",
    "\n",
    "    max_data = max(signal)\n",
    "    min_data = min(signal)\n",
    "    \n",
    "    imfs = emddev.emd(signal, min_data, max_data, max_modes, max_siftings)\n",
    "    \n",
    "    imf1 = utils.reverse_normalization(imfs[0], min_data, max_data, len(signal))\n",
    "    imf2 = utils.reverse_normalization(imfs[1], min_data, max_data, len(signal))\n",
    "    residue = utils.reverse_normalization(imfs[-1], min_data, max_data, len(signal))\n",
    "    return signal - imf1 - imf2 - residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output imf x data\n",
    "def get_IMF(signal, max_modes = 15):\n",
    "    ensembles = 100\n",
    "    ensembles_per_process = 10\n",
    "    max_siftings = 200\n",
    "    end_time = 10\n",
    "    sample_freq = 250\n",
    "\n",
    "    max_data = max(signal)\n",
    "    min_data = min(signal)\n",
    "    \n",
    "    return emddev.emd(signal, min_data, max_data, max_modes, max_siftings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_average(x, window = 5):\n",
    "    avg_x = np.zeros(len(x) // window)\n",
    "    for i in range(0, (len(x) // window)):\n",
    "        w_step = i * window\n",
    "        avg_x[i] = np.average(x[w_step:(w_step + 4)])\n",
    "    return avg_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in an array of form measurement x data x sensor\n",
    "# Return array of form measurement x data x sensor\n",
    "def filter_signals(data):\n",
    "    f = np.zeros(data.shape)\n",
    "    # Calculate all IMFs for all sensors\n",
    "    for m, measurement in enumerate(data):\n",
    "        for s, sensor in enumerate(measurement.T):\n",
    "            f[m, :,s] = IMF_filter(sensor)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IMFs(data, num_imfs=4):\n",
    "    # Calculate all IMFs for all sensors\n",
    "    list_imfs = np.zeros((data.shape[0], data.shape[2], num_imfs, data.shape[1]))\n",
    "    for m, measurement in enumerate(data):\n",
    "        for s, sensor in enumerate(measurement.T):\n",
    "            imfs = get_IMF(sensor)\n",
    "            num_cols = 4\n",
    "            if imfs.shape[0] < 4:\n",
    "                num_cols = imfs.shape[0]\n",
    "            list_imfs[m, s, :num_cols, :] = imfs[0:num_cols] \n",
    "    return list_imfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_HHT(imfs):\n",
    "    err_idx = np.array([])\n",
    "    frequencies = np.zeros(imfs.shape)\n",
    "    amplitudes = np.zeros(imfs.shape)\n",
    "    for m, measurement in enumerate(imfs):\n",
    "        for s, sensor in enumerate(measurement):\n",
    "                try:\n",
    "                    f, a = nhht.nhht(sensor, 250)\n",
    "                except:\n",
    "                    print(\"Error on measurement \" + str(m) + \"sensor \" + str(s))\n",
    "                    err_idx = np.append(err_idx, m)\n",
    "                frequencies[m,s,:,:] = f\n",
    "                amplitudes[m,s,:,:] = a\n",
    "    return frequencies, amplitudes, err_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERP(amplitudes, divider=3, initial=1, cutoff=1, fs=250):\n",
    "    \n",
    "    a = np.square(amplitudes)\n",
    "    # Calculate mean before event\n",
    "    r_i = a[:, (initial * fs):(divider * fs)].mean(axis=1)\n",
    "    a_j = np.zeros(a[:, (divider * fs):-(cutoff * fs)].shape)\n",
    "    for r, row in enumerate(a[:, (divider * fs):-(cutoff * fs)]):\n",
    "        a_j[r, :] = [100 * ((a_j_t - r_i[r]) / r_i[r]) for a_j_t in row]\n",
    "    # Calculate mean after event\n",
    "    #a_j = a[:, (divider * fs):-(cutoff * fs)].mean(axis=1)\n",
    "    # Calculate event related potential for given amplitudes\n",
    "    #erp =  np.mean(100 * ((a_j - r_i) / r_i))\n",
    "    erp = a_j.mean(axis=1)\n",
    "    \n",
    "    return erp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ERP(amplitudes):\n",
    "    erps = np.zeros((amplitudes.shape[0], amplitudes.shape[1], 4))\n",
    "    for m, measurement in enumerate(amplitudes):\n",
    "        for a, amplitude in enumerate(measurement):\n",
    "                erps[m,a,:] = ERP(amplitude)\n",
    "    return erps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_signals(folder):\n",
    "    path = folder\n",
    "    files = []\n",
    "    count = 0\n",
    "    for i in os.listdir(path):\n",
    "        files.append(i)\n",
    "    data = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(path, file), index_col=0)\n",
    "        data.append(df.as_matrix())\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_erp(signal):\n",
    "    err_idx = np.array([])\n",
    "    #print(\"Calculating fd\")\n",
    "    fd = filter_signals(signal)\n",
    "    fd = fd[:,125:-125,:]\n",
    "    print(\"Calculating imfs\")\n",
    "    imfs = calculate_IMFs_alt(signal)\n",
    "    #imfs = imfs[:,:,:,100:-100]\n",
    "    print(\"Calculating erps\")\n",
    "    erps = np.zeros((imfs.shape[0] - 3, imfs.shape[1], imfs.shape[2]))\n",
    "    for m, measurement in enumerate(imfs[2:-1,:,:]):\n",
    "        for s, sensor in enumerate(measurement):\n",
    "                try:\n",
    "                    _, a = nhht.nhht(sensor, 250)\n",
    "                except:\n",
    "                    err_idx = np.append(err_idx, m)\n",
    "                erps[m,s,:] = ERP(a[:, 125:-125])\n",
    "    return imfs, erps, err_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_SVM(erps):\n",
    "    train = np.vstack(tuple(erps))\n",
    "    X, Y = train[:, 0:-1], train[:, -1].astype(int)\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(kernel='rbf'))\n",
    "    scores = cross_val_score(clf, X, Y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def grid_search_SVM(erps):\n",
    "    train = np.vstack(tuple(erps))\n",
    "    np.random.shuffle(train)\n",
    "    X_train, Y_train = train[:, 0:-1], train[:, -1].astype(int)\n",
    "    \n",
    "    tuned_parameters2 = [{'kernel': ['rbf'], 'gamma': [0.0001,0.001,0.01,1.0,2],\n",
    "                         'C': [1,2,4,6,8,10]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1, 0.1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                         'C': [0.1, 1, 10, 100, 1000, 10000]},\n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    grid = GridSearchCV(estimator=svm.SVC(C=1), param_grid=tuned_parameters, cv=10, scoring='accuracy', n_jobs=-1) \n",
    "    grid.fit(scaler.transform(X_train), Y_train)\n",
    "\n",
    "    # View the accuracy score\n",
    "    print('Best score for data1:', grid.best_score_)\n",
    "    # View the best parameters for the model found using grid search\n",
    "    print('Best C:',grid.best_estimator_.C) \n",
    "    print('Best Kernel:', grid.best_estimator_.kernel)\n",
    "    print('Best Gamma:', grid.best_estimator_.gamma)\n",
    "    pprint(grid.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"exp_data/joachim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = load_all_signals(path + \"/right\")\n",
    "neutral = load_all_signals(path + \"/neutral\")\n",
    "left = load_all_signals(path + \"/left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1500, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Calculating fd\")\n",
    "p = Pool(3)\n",
    "fd1, fd2, fd3 = p.map(filter_signals, [neutral[:,125:-125,:], right[:,125:-125,:], left[:,125:-125,:]])\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(3)\n",
    "imfs1, imfs2, imfs3 = p.map(calculate_IMFs, [fd1, fd2, fd3])\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(3)\n",
    "hht1, hht2, hht3 = p.map(calculate_HHT, [imfs1[:,:,:,125:-125], imfs2[:,:,:,125:-125], imfs3[:,:,:,125:-125]])\n",
    "p.close()\n",
    "p.join()\n",
    "freq1, ampl1, ei1 = hht1\n",
    "freq2, ampl2, ei2 = hht2\n",
    "freq3, ampl3, ei3 = hht3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1250, 8) (50, 8, 4, 1250) (50, 8, 4, 1000) (50, 8, 4, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(fd1.shape, imfs1.shape, freq1.shape, ampl1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path + '/fd1', fd1)\n",
    "np.save(path + '/fd2', fd2)\n",
    "np.save(path + '/fd3', fd3)\n",
    "\n",
    "np.save(path + '/imfs1', imfs1)\n",
    "np.save(path + '/imfs2', imfs2)\n",
    "np.save(path + '/imfs3', imfs3)\n",
    "\n",
    "np.save(path + '/freq1', freq1)\n",
    "np.save(path + '/freq2', freq2)\n",
    "np.save(path + '/freq3', freq3)\n",
    "\n",
    "np.save(path + '/ampl1', ampl1)\n",
    "np.save(path + '/ampl2', ampl2)\n",
    "np.save(path + '/ampl3', ampl3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
